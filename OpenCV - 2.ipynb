{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tranformations of Images\n",
    "\n",
    "There are basically two types of image transforms, affine, non-affine.\n",
    "\n",
    "**Affine** are those in which the parallelism, shape and general structure of the image is conserved\n",
    "Example of such transforms: Translations, Rotations, etc.\n",
    "    \n",
    "**Non-affine** are those in which only the collinearity and incidence are maintained, all other properties of the image might be lost.\n",
    "Example of such transfroms: Sharpening, Perspective views, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translations\n",
    "\n",
    "This is an affine transform that simply shift the position of an image\n",
    "\n",
    "We use cv2.warpAffine to implement these transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('./images/input.jpg')\n",
    "\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "quarter_height, quarter_width = height/4, width/4\n",
    "\n",
    "#      | 1 0 Tx |\n",
    "#  T = | 0 1 Ty |\n",
    "\n",
    "# T is our translation matrix\n",
    "T = np.float32([[1,0,quarter_width], [0,1,quarter_height]])\n",
    "\n",
    "#We use warpAffine to transform the image using the matrix T\n",
    "img_translation  = cv2.warpAffine(image, T, (width, height))\n",
    "\n",
    "cv2.imshow('Translation', img_translation)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.     0.   155.5 ]\n",
      " [  0.     1.   103.75]]\n"
     ]
    }
   ],
   "source": [
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotations\n",
    "This is an affine transform involving rotating the image through an angle\n",
    "\n",
    "cv2.getRotationMatrix2D(rotation_center_x, rotation_center_y, angle of rotation, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/input.jpg')\n",
    "height, width  = img.shape[:2]\n",
    "\n",
    "# Divide by two to rotate the image about it's center\n",
    "rotation_matrix = cv2.getRotationMatrix2D((width/2, height/2), 90, .5)\n",
    "\n",
    "rotated_img = cv2.warpAffine(img, rotation_matrix, (width, height))\n",
    "\n",
    "cv2.imshow('Rotated image', rotated_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Another method for rotating an image by 90 degrees preserving the scale\n",
    "and with no cropping required**\n",
    "\n",
    "We can use the cv2.transpose function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other method\n",
    "img = cv2.imread('./images/input.jpg')\n",
    "\n",
    "rotated_img = cv2.transpose(img)\n",
    "\n",
    "cv2.imshow('Rotation successful', rotated_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now do a horizontal flip\n",
    "flipped = cv2.flip(img, 1)\n",
    "\n",
    "# For performing a vertical flip change the second argument of flip\n",
    "# function to 0\n",
    "\n",
    "cv2.imshow('Horizontal Flip', flipped)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling, re-sizing and interpolations\n",
    "\n",
    "Re-sizing is very easy using the cv2.resize function, it's arguments are:\n",
    "\n",
    "cv2.resize(image, dsize(output image size), xscale, yscale, interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/input.jpg')\n",
    "\n",
    "# Let's make the image 3/4 of the original size\n",
    "img_scaled = cv2.resize(img, None, fx = 0.75, fy = 0.75)\n",
    "cv2.imshow('Scaling by Linear Interpolation', img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Let's make it double the size, for making an image larger,\n",
    "# we usually prefer cubic interpolation\n",
    "img_scaled = cv2.resize(img, None, fx = 2, fy = 2, interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imshow('Scaling by Cubic Interpolation',img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Let's skew the re-sizing by setting custom dimensions\n",
    "img_scaled = cv2.resize(img, (900,400), interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow('Scaling for Skewed Size', img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Pyramids\n",
    "\n",
    "Useful when scaling images in object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('./images/input.jpg')\n",
    "\n",
    "smaller = cv2.pyrDown(image)\n",
    "larger = cv2.pyrUp(smaller)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "\n",
    "cv2.imshow('Smaller ', smaller)\n",
    "cv2.imshow('Larger ', larger )\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('./images/input.jpg')\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Let's get the starting pixel coordinates\n",
    "start_row, start_col = int(height*0.25), int(width*0.25)\n",
    "\n",
    "# Let's get the ending pixel coordinates\n",
    "end_row, end_col = int(height * 0.75), int(width*0.75)\n",
    "\n",
    "cropped = image[start_row:end_row, start_col:end_col]\n",
    "\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Cropped Image', cropped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic Operations\n",
    "These are simple operations that allow us to directly add or subtract color intensity.\n",
    "\n",
    "Calculates the per-element operation of 2 arrays. The overall effect is increasing or decreasing brightness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/input.jpg')\n",
    "\n",
    "M = np.ones(img.shape, dtype = np.uint8)*75\n",
    "\n",
    "# Added shows brighter image\n",
    "\n",
    "added = cv2.add(img, M)\n",
    "cv2.imshow('Added', added)\n",
    "\n",
    "# Subtracted shows darker image\n",
    "\n",
    "subtracted = cv2.subtract(img, M)\n",
    "cv2.imshow('Subtracted', subtracted)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[75, 75, 75],\n",
       "        [75, 75, 75],\n",
       "        [75, 75, 75],\n",
       "        ...,\n",
       "        [75, 75, 75],\n",
       "        [75, 75, 75],\n",
       "        [75, 75, 75]],\n",
       "\n",
       "       [[75, 75, 75],\n",
       "        [75, 75, 75],\n",
       "        [75, 75, 75],\n",
       "        ...,\n",
       "        [75, 75, 75],\n",
       "        [75, 75, 75],\n",
       "        [75, 75, 75]],\n",
       "\n",
       "       [[75, 75, 75],\n",
       "        [75, 75, 75],\n",
       "        [75, 75, 75],\n",
       "        ...,\n",
       "        [75, 75, 75],\n",
       "        [75, 75, 75],\n",
       "        [75, 75, 75]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[75, 75, 75],\n",
       "        [75, 75, 75],\n",
       "        [75, 75, 75],\n",
       "        ...,\n",
       "        [75, 75, 75],\n",
       "        [75, 75, 75],\n",
       "        [75, 75, 75]],\n",
       "\n",
       "       [[75, 75, 75],\n",
       "        [75, 75, 75],\n",
       "        [75, 75, 75],\n",
       "        ...,\n",
       "        [75, 75, 75],\n",
       "        [75, 75, 75],\n",
       "        [75, 75, 75]],\n",
       "\n",
       "       [[75, 75, 75],\n",
       "        [75, 75, 75],\n",
       "        [75, 75, 75],\n",
       "        ...,\n",
       "        [75, 75, 75],\n",
       "        [75, 75, 75],\n",
       "        [75, 75, 75]]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bitwise Operations and Masking\n",
    "\n",
    "To demonstrate these operations let's create some simple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# If you're wondering why only two dimensions, well this is a grayscale image, \n",
    "# if we doing a colored image, we'd use \n",
    "# rectangle = np.zeros((300, 300, 3),np.uint8)\n",
    "\n",
    "# Making a sqare\n",
    "square = np.zeros((300, 300), np.uint8)\n",
    "cv2.rectangle(square, (50, 50), (250, 250), 255, -2)\n",
    "cv2.imshow(\"Square\", square)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Making a ellipse\n",
    "ellipse = np.zeros((300, 300), np.uint8)\n",
    "cv2.ellipse(ellipse, (150, 150), (150, 150), 30, 0, 180, 255, -1)\n",
    "cv2.imshow(\"Ellipse\", ellipse)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with some bitwise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows only where they intersect\n",
    "And = cv2.bitwise_and(square, ellipse)\n",
    "cv2.imshow(\"AND\", And)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Shows where either square or ellipse is \n",
    "bitwiseOr = cv2.bitwise_or(square, ellipse)\n",
    "cv2.imshow(\"OR\", bitwiseOr)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Shows where either exist by itself\n",
    "bitwiseXor = cv2.bitwise_xor(square, ellipse)\n",
    "cv2.imshow(\"XOR\", bitwiseXor)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Shows everything that isn't part of the square\n",
    "bitwiseNot_sq = cv2.bitwise_not(square)\n",
    "cv2.imshow(\"NOT - square\", bitwiseNot_sq)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "### Notice the last operation inverts the image totally\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OpenCV to run WebCam : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('My camera', frame)\n",
    "    if(cv2.waitKey(1) == 13): # 13 is the Enter Key\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1: Turning your WebCam feed into a Live Pencil Drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def sketch(image):\n",
    "    # Convert image to grayscale\n",
    "    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #Clean up image using Gaussian Blur\n",
    "    img_gray_blur = cv2.GaussianBlur(img_gray, (5,5), 0)\n",
    "    \n",
    "    # Extract edges\n",
    "    canny_edges = cv2.Canny(img_gray_blur, 10, 70)\n",
    "    \n",
    "    # Do an invert binarize the image\n",
    "    ret, mask = cv2.threshold(canny_edges, 70, 255, cv2.THRESH_BINARY_INV)\n",
    "    return mask\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('My camera', sketch(frame))\n",
    "    if(cv2.waitKey(1) == 13): # 13 is the Enter Key\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
